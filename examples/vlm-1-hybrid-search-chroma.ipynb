{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid document search with VLM-1 and ChromaDB \n",
    "\n",
    "We're going to extend our workflow for finance presentations to incorporate [Chroma DB](https://www.trychroma.com/), allowing us to store \n",
    "the embedded documents and extracted metadata simultaneously in a single data store for a variety of \n",
    "different retrieval flows. For instance, we'll be able to perform filtered language search using our schema.\n",
    "\n",
    "As before, we're going to use slides from [SEC Edgar database](https://www.sec.gov/edgar.shtml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "!pip install requests Pillow chromadb open-clip-torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the financial data example, we ping the API endpoint and make sure its working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "VLM_BASE_URL = \"https://api.vlm.run/v1\"\n",
    "response = requests.get(f\"{VLM_BASE_URL}/health\")\n",
    "response.raise_for_status()\n",
    "assert response.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VLM_API_KEY = os.getenv(\"VLM_API_KEY\", None)\n",
    "if VLM_API_KEY is None:\n",
    "    VLM_API_KEY = input()\n",
    "print(f\"Using API key: {VLM_API_KEY[:4]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-API-Key\": VLM_API_KEY,\n",
    "}\n",
    "response = requests.get(f\"{VLM_BASE_URL}/models\", headers=headers)\n",
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borrow the helper functions from financial data notebook so we don't need other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../vlm_tools/image.py\n",
    "import json\n",
    "from base64 import b64encode\n",
    "from io import BytesIO\n",
    "from typing import Literal, Union\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def pprint(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "\n",
    "def encode_image(\n",
    "    image: Image.Image, format: Literal[\"PNG\", \"JPEG\"] = \"PNG\"\n",
    ") -> Union[str, bytes]:\n",
    "    \"\"\"Convert an image to a base64 string.\"\"\"\n",
    "    buffered = BytesIO()\n",
    "    image_format = image.format or format\n",
    "    image.save(buffered, format=image_format)\n",
    "    img_str = b64encode(buffered.getvalue()).decode()\n",
    "    return f\"data:image/{image_format.lower()};base64,{img_str}\"\n",
    "\n",
    "\n",
    "def download_image(url: str) -> Image.Image:\n",
    "    \"\"\"Download an image from a URL.\"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:106.0) Gecko/20100101 Firefox/106.0\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    }\n",
    "    bytes = BytesIO(requests.get(url, headers=headers).content)\n",
    "    bytes.seek(0)\n",
    "    return Image.open(bytes).convert(\"RGB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def vlm(image: Image.Image, domain: str):\n",
    "    \"\"\"Send an image to the VLM API.\"\"\"\n",
    "    data = {\n",
    "        \"model\": \"vlm-1\",\n",
    "        \"domain\": domain,\n",
    "        \"image\": encode_image(image),\n",
    "    }\n",
    "    response = requests.post(f\"{VLM_BASE_URL}/generate\", headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def vlm_visualize(image: Union[Image.Image, str, Path], domain: str):\n",
    "    \"\"\"Send an image to the VLM API and display the result.\"\"\"\n",
    "    if isinstance(image, str) and image.startswith(\"http\"):\n",
    "        image = download_image(image)\n",
    "    elif isinstance(image, (str, Path)):\n",
    "        if not Path(image).exists():\n",
    "            raise FileNotFoundError(f\"File not found {image}\")\n",
    "        image = Image.open(str(image)).convert(\"RGB\")\n",
    "    elif isinstance(image, Image.Image):\n",
    "        image = image.convert(\"RGB\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid image, must be a path, PIL Image or URL\")\n",
    "\n",
    "    display(image)\n",
    "    result = vlm(image, domain)\n",
    "    pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS = [\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve001.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve002.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve003.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve004.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve005.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve006.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve007.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve008.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve009.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve010.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve011.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve012.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve013.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve014.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve015.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve016.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve017.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve018.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve019.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve020.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve021.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve022.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve023.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve024.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve025.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve026.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve027.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve028.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve029.jpg\",\n",
    "    \"https://www.sec.gov/Archives/edgar/data/230557/000023055724000007/sigifirstquarter2024inve030.jpg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's extract some information from a financial presentation on [SEC EDGAR](https://www.sec.gov/edgar/search-and-access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = URLS[10]\n",
    "vlm_visualize(url, domain=\"document.presentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now lets set up our chroma DB and embed a few of these slides, then try out a language query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
    "from chromadb.utils.data_loaders import ImageLoader\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "data_loader = ImageLoader()\n",
    "embedding_function = OpenCLIPEmbeddingFunction()\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"earnings_slides\",\n",
    "    embedding_function=embedding_function,\n",
    "    data_loader=data_loader)\n",
    "\n",
    "url_base_ids = [url.split('/')[-1].split('.')[0] for url in URLS]\n",
    "\n",
    "# Need to download the urls locally first:\n",
    "url_paths = []\n",
    "numpy_images = []\n",
    "for url in URLS:\n",
    "    image = download_image(url)\n",
    "    url_path = url.split('/')[-1]\n",
    "    image.save(f\"{url_path}\")\n",
    "    url_paths.append(url_path)\n",
    "    # convert PIL image to numpy\n",
    "    numpy_images.append(np.array(image))\n",
    "\n",
    "collection.add(\n",
    "    ids = url_paths,\n",
    "    images = numpy_images,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"DPW mix pie chart\"]\n",
    ")\n",
    "\n",
    "# display the top result image\n",
    "display(Image.open(results['ids'][0][0]))\n",
    "\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[\"Net premiums written pie chart\"]\n",
    ")\n",
    "\n",
    "# display the top result image\n",
    "display(Image.open(results['ids'][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the top results for each query are somewhat reasonable, they aren't actually what we're looking for. The first query 'DPW mix pie chart' returns a slide containing a pie chart, just not the one we were looking for. The second query ('net premiums written pie chart') return a slide referencing net premiums (there are several in this deck) but not the specific pie chart we want. \n",
    "\n",
    "We can still make this work by incorporating metadata alongside our documents. Chroma supports filtering by metadata fields, which we can populate automatically with our API for Hybrid search. Let's ask VLM-1 to flag all of the documents containing a Pie Chart in the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_subset = URLS[5:15]\n",
    "numpy_images_subset = numpy_images[5:15]\n",
    "\n",
    "vlm_full_results = {}\n",
    "\n",
    "for url in URLS:\n",
    "    image = download_image(url)\n",
    "    vlm_full_results[url] = vlm(image, domain=\"document.presentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the metadata to get the presence of absence of a pie chart\n",
    "plot_metadata = {}\n",
    "for key, result in vlm_full_results.items():\n",
    "    plot_metadata[key] = {'has_pie_chart' : False}\n",
    "    if result['plots'] is not None:\n",
    "        for plot in result['plots']:\n",
    "            if plot['type'] == 'pie':\n",
    "                plot_metadata[key]['has_pie_chart'] = True\n",
    "\n",
    "print(json.dumps(plot_metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a new collection, this time including our metadata dict alongside the vector for each document. We'll just ask for 'net premiums written' and filter by 'has_pie_chart' = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just using 10 slides to save time\n",
    "url_subset = URLS[5:15]\n",
    "numpy_images_subset = numpy_images[5:15]\n",
    "metadata_subset = {key: value for key, value in plot_metadata.items() if key in url_subset}\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"earnings_slides_with_metadata\",\n",
    "    embedding_function=embedding_function,\n",
    "    data_loader=data_loader)\n",
    "\n",
    "collection.add(\n",
    "    ids = url_subset,\n",
    "    images = numpy_images_subset,\n",
    "    metadatas = [value for value in metadata_subset.values()] # should be a list of dicts\n",
    ")\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[\"net premiums written\"],\n",
    "    where={\"has_pie_chart\" : True}\n",
    ")\n",
    "\n",
    "# display the top result image\n",
    "top_1_image_id = results['ids'][0][0]\n",
    "display(download_image(top_1_image_id))\n",
    "\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[\"DPW Mix\"],\n",
    "    where={\"has_pie_chart\" : True}\n",
    ")\n",
    "\n",
    "# display the top result image\n",
    "top_1_image_id = results['ids'][0][0]\n",
    "display(download_image(top_1_image_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only pie charts to pick from, we see the first and second results show pie charts for net premiums and DPW mix, respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
